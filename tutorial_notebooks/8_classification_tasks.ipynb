{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97f60c7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/IPML/blob/master/tutorial_notebooks/9_classification_tasks.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f867e0",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "We continue using the HMEQ classification data sets. Beyond loading standard libraries, the following code block reads the data from our [GitHub repository](https://github.com/Humboldt-WI/IPML/tree/main) and performs some preprocessing operations, which we introduced in earlier tutorials. Since future tutorials will need the same functionality, we encapsulate the code in a function called `get_credit_risk_data()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load standard libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We put all codes to retrieve and prepare our credit risk data into a custom function\n",
    "def get_credit_risk_data(outlier_factor=2):\n",
    "    # Load credit risk data directly from GitHub\n",
    "    data_url = 'https://raw.githubusercontent.com/Humboldt-WI/bads/master/data/hmeq.csv'\n",
    "    hmeq = pd.read_csv(data_url)\n",
    "\n",
    "    # Code categories properly \n",
    "    hmeq['REASON'] = hmeq['REASON'].astype('category')\n",
    "    hmeq['JOB'] = hmeq['JOB'].astype('category')\n",
    "    hmeq = pd.get_dummies(hmeq, drop_first=True)  \n",
    "    \n",
    "    # Code the target variable properly\n",
    "    hmeq['BAD'] = hmeq['BAD'].astype('bool')\n",
    "    \n",
    "    # Downcast numerical columns to save memory\n",
    "    ix_numeric_columns = hmeq.select_dtypes(include=np.number).columns\n",
    "    hmeq[ix_numeric_columns] = hmeq[ix_numeric_columns].astype('float32')\n",
    "\n",
    "    # Handle missing values:\n",
    "    # 1. The feature DEBTINC is important but suffers many missing values. Blindly replacing these missing values\n",
    "    #    would introduce bias and harm any model trained on the data. To avoid this, we add a dummy variable\n",
    "    #    to indicate whether the feature value was missing or not.\n",
    "    hmeq['D2I_miss'] = hmeq['DEBTINC'].isna().astype('category')\n",
    "    # 2. For the other numerical features, we use the median to impute missing values. For the categorical features\n",
    "    imputer = SimpleImputer(strategy='median')  # Create an imputer object with the strategy 'median'\n",
    "    hmeq[ix_numeric_columns] = imputer.fit_transform(hmeq[ix_numeric_columns])  \n",
    "    # 3. For the categorical features, we use the mode to impute missing values\n",
    "    ix_cat = hmeq.select_dtypes(include=['category']).columns  # Get an index of the categorical columns\n",
    "    for c in ix_cat:  # Process each category\n",
    "        hmeq.loc[hmeq[c].isna(), c ] = hmeq[c].mode()[0]  # the index [0] is necessary as the result of calling mode() is a Pandas Series\n",
    "    \n",
    "    # Truncate outliers among numerical features\n",
    "    if outlier_factor > 0:\n",
    "        for col in ix_numeric_columns:\n",
    "            if col not in ['DELINQ', 'DEROG']:  # We do not truncate these features as their distribution if strongly skewed such outlier trunction would leave us with a constant feature\n",
    "                q1 = hmeq[col].quantile(0.25)\n",
    "                q3 = hmeq[col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                lower_bound = q1 - outlier_factor * iqr\n",
    "                upper_bound = q3 + outlier_factor * iqr\n",
    "                hmeq[col] = hmeq[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    hmeq[ix_numeric_columns] = scaler.fit_transform(hmeq[ix_numeric_columns])\n",
    "\n",
    "    # Separate the target variable and the feature matrix\n",
    "    y = hmeq.pop('BAD')\n",
    "    X = hmeq\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Call the function to retrieve the data\n",
    "X, y = get_credit_risk_data()   \n",
    "\n",
    "# Preview the data\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd477e7a-c3c4-4952-b50b-4cd3d866906c",
   "metadata": {},
   "source": [
    "# Binary classification for PD modeling\n",
    "Having prepared our data, we can proceed with predictive modeling. The lecture introduced the general classification setup and the logistic regression model. Let's revisit these elements in detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2ea9f-4363-42a7-a5a3-ec2d037cff01",
   "metadata": {},
   "source": [
    "## Excercise 1: Plotting data for classification\n",
    "You will remember the many plots we came across when discussing regression. We also saw some analog plots for classification problems in the lecture. One of them was a 2d scatter plot displaying the bi-variate relationship between selected features and the binary target variable. \n",
    "\n",
    "![Classification problem in 2D](https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/main/resources/2d_classification_problem.png)\n",
    "\n",
    "Your first task is to create a similar plot for the credit data. In principle, you can select any combination of features that you like.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056e886-fb90-4846-a961-fe6543a6ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d1ece",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "Time to estimate our first classification model. We will use logistic regression. Think of it as an extension of linear regression for cases in which we work with a binary target variable. Just as in linear regression, logistic regression involves model training on labelled data. The below code uses the `sklearn` library to train a logistic regression-based classification model. In case you receive a warning message when running the code (i.e., *Convergence warning*), please ignore this message for now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=123)  # the random_state ensures that we get the same results when re-running this cell multiple times\n",
    "model.fit(X, y)  # Train the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab494b5",
   "metadata": {},
   "source": [
    "Note that the `sklearn` implementation does not provide an informative summary, as did the library `statsmodels`, which we used to [illustrate regression analysis](https://github.com/Humboldt-WI/IPML/blob/master/tutorial_notebooks/5_SML_for_regression_solutions.ipynb). You can still access the estimated coefficients and the intercept using the attributes `coef_` and `intercept_` of the fitted model. However, $R^2$, p-values or confidence intervals are not available. In brief, this is because `sklearn` is designed to support prediction. Let's demonstrate how to compute predictions using the trained model. For simplicity, we compute prediction for the training data. You already learnt that this is inappropriate and that we should use the *holdout* method instead. We will talk about model evaluation in a future notebook. Here, we keep things simple and compute predictions for the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ebea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated coefficients:\\n\", model.coef_)  # The coefficients of the model \n",
    "print(\"\\nIntercept coefficients:\\n\", model.intercept_)  # The intercept of the model   \n",
    "yhat = model.predict(X)  # simple way to compute predictions using logistic regression and any other machine learning model in sklearn \n",
    "print(\"\\nPredictions:\\n\", yhat)  # The predictions of the model   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbac446",
   "metadata": {},
   "source": [
    "## Diagnosing predictions\n",
    "The above output hints at an issue with our predictions. We discuss this part in the tutorial and *debug* the predictions to fully understand what is going on when we call the function `predict()` and when this function is useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be completed in class...\n",
    "\n",
    "# Unique predicted values\n",
    "\n",
    "# Calculate probabilistic predictions by hand\n",
    "# a. Extract the coefficients and intercept from the trained model\n",
    "\n",
    "\n",
    "# b. Compute the linear combination of the features and the coefficients\n",
    "\n",
    "\n",
    "# c. Apply the logistic function to compute the probabilities\n",
    "\n",
    "\n",
    "# Display the first few probabilities\n",
    "\n",
    "\n",
    "# Compute discrete class predictions by comparing the probabilities to a cut-off of 0.5\n",
    "\n",
    "\n",
    "# The proper way to obtain the probabilities in sklearn\n",
    "\n",
    "\n",
    "# Compare the predictions from the model and the predictions by hand\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecef85",
   "metadata": {},
   "source": [
    "## Visualizing the logistic regression\n",
    "We complete our examination of the logistic regression model with a visualization of its behavior. To that end, we use a helper function `plot_logit_decision_surface()`. You can find the code below. It is quite comprehensive and we recommend you simply execute the code without worring about the function implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb227a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logit_decision_surface(model, X, y):\n",
    "    '''\n",
    "        Visualization of logistic regression in 2D\n",
    "        \n",
    "        Creates a plot depicting the distribution of the input\n",
    "        data along two dimensions and the probability predictions\n",
    "        of a logistic regression model. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model :   An instance of the sklearn class LogisticRegression,  which        \n",
    "                  has been trained on the input data.\n",
    "\n",
    "        X  :      2D numpy array with the feature values\n",
    "\n",
    "        y     :   1D numpy array containing the binary target variable. \n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The function does not return a result. It's purpose is to visualize \n",
    "        logistic regression model. The corresponding plot is the only output.\n",
    "    '''\n",
    "    import numpy as np \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if len(model.coef_.ravel())!=2:\n",
    "        raise Exception('Please estimate a logit model using only two features!')\n",
    "    \n",
    "    if X.shape[1]!=2:\n",
    "        raise Exception('The function supports only 2D data!')\n",
    "\n",
    "    eps = 2  # tolerance parameter \n",
    "\n",
    "    # Create hypothetical data points spanning the entire range of feature values.\n",
    "    # We need these to get from our logistic regression model a probability prediction\n",
    "    # for every possible data point\n",
    "    xx, yy = np.mgrid[(np.min(X[:,0])-eps):(np.max(X[:,0])+eps), (np.min(X[:,1])-eps):(np.max(X[:,1])+eps)]\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    \n",
    "    w = model.coef_.ravel()  # estimated regression coefficients\n",
    "    b = model.intercept_  # estimated intercept of the logistic regression model\n",
    "\n",
    "    # Compute probability predictions over the entire space of possible feature values\n",
    "    # In the interest of robustness, we manually compute the logistic regression predictions\n",
    "    # using the regression coefficients extracted above\n",
    "    probs = 1/(1+np.exp(-(np.dot(grid, w.reshape(2,-1))+b))).reshape(xx.shape)\n",
    "\n",
    "    # We are finally ready to create our visualization\n",
    "    f, ax = plt.subplots(figsize=(8, 6))  # new figure\n",
    "    # Contour plot of the probability predictions across the entire feature range\n",
    "    contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\", vmin=0, vmax=1)  \n",
    "    ax_c = f.colorbar(contour)\n",
    "    ax_c.set_label(\"$\\hat{p}(y=1|X)$\")\n",
    "    ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "    # Scatter plot of the actual data\n",
    "    ax.scatter(X[:,0], X[:,1], c=y, s=50, cmap=\"RdBu\", vmin=0, vmax=1,\n",
    "               edgecolor=\"white\", linewidth=1);\n",
    "    plt.xlabel('$X_1$')\n",
    "    plt.ylabel('$X_2$')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5be8b3",
   "metadata": {},
   "source": [
    "Further, to create a more interesting plot, it makes sense to depict the behavior of logistic regression when processing an easier data set. Specifically, we will generate synthetic, 2-dimensional data in which the two classes are easily separated using a linear classifier. You can later try to create a similar plot for our credit data if you like, but be warned, it would not look as nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f297996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic 2D data for classification. \n",
    "# Note that we used the same approach in our tutorial on clustering\n",
    "from sklearn.datasets import make_blobs\n",
    "tmp_X, tmp_y = make_blobs(n_samples=500, n_features=2, centers=2, cluster_std=1, random_state=123)\n",
    "\n",
    "# Fit a logit model to the data (same code as above)\n",
    "tmp_reg = LogisticRegression(random_state=123).fit(tmp_X, tmp_y)  # Train the mode\n",
    "\n",
    "# Call our helper function for visualization\n",
    "plot_logit_decision_surface(tmp_reg, tmp_X, tmp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7202a-455b-44a3-9d16-78c40a5ea1a3",
   "metadata": {},
   "source": [
    "## Exercise 2: Probabilistic and discrete class prediction using the logistic regression classifier\n",
    "The above demo has introduced the method `predict_proba()`, which any `sklearn`-based classification model supports. It gives you a an $n \\times k$ array of probability predictions, where $n$ is the number of data points and $k$ is the number of classes. In our case, $k=2$. The first column of the array contains the probability of the negative class, and the second column contains the probability of the positive class. Classifiers also support a second method called `predict()`, which returns the predicted class labels. In our context these would be either 0 or 1, to denote the negative and positive class, respectively. Finally, an easy way to assess a trained classification models is to use the method `score()`. It returns the accuracy of the model, which is the proportion of correctly predicted labels. Let's explore these methods in more detail by solving the following tasks.\n",
    "\n",
    "- Apply the method `score()` to the trained logistic regression classifier, which you can access through the variable `model`. Print the result as a percentage.\n",
    "- Apply the method `predict()` to the training data and store the result in a variable called `y_pred`. Write code to compute the accuracy of the model manually. Compare the result with the output of the `score()` method.\n",
    "- Apply the method `predict_proba()` to the training data and store the result in a variable called `y_pred_proba`. Write code to compute the accuracy of the model manually. Compare the result with the output of the `score()` method.\n",
    "- Reusing the variable `y_pred_proba` computed in the previous exercise, write code to compute the mean squared error between your binary target variable `y` and the predicted probabilities `y_pred_proba`. This score is known as the *Brier Score* in the context of classification. \n",
    "\n",
    "**More advanced exercise (optional):**\n",
    "- To set the performance of the logit model into context, compute the accuracy of a dummy classifier that always predicts the most frequent class. Compare the accuracy of the dummy classifier with the accuracy of the logistic regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions to Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aca48d",
   "metadata": {},
   "source": [
    "# Measures of classifier performance\n",
    "In the lecture, we discussed the confusion matrix and the ROC curve as tools to evaluate classification models. We will now demonstrate how to use these tools in Python. The `sklearn` library provides several functions to evaluate the performance of a classifier. In general, functionality for model evaluation is available in the module `sklearn.metrics`.\n",
    "\n",
    "## Confusion matrix\n",
    "The confusion matrix of a binary classifier is a 2x2 matrix that contains four values: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). The following image illustrates the confusion matrix and some common performance measures derived from it. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Humboldt-WI/demopy/main/confusion_matrix.PNG\" width=\"854\" height=\"480\" alt=\"Confusion Matrix\">\n",
    "\n",
    "Let us produce a confusion matrix for our logistic regression model. To that end, we make use of the class `ConfusionMatrixDisplay` from the module `sklearn.metrics`. It is a convenient way to visualize the confusion matrix and offers two interfaces. You can either pass the true and predicted labels to the method `from_predictions()` or directly pass the trained classifier together with testing data to the method `from_estimator()`. We will demonstrate both approaches using the existing variables `model` (our trained logistic regression model) as well as `X` and `y`. Before moving on, note that `sklearn` also provides function to simply calculate the confusion matrix (i.e., without visualization). To achieve this, you can use the function `confusion_matrix()` from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant class\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Compute predictions\n",
    "yhat_class = model.predict(X)  # this produces discrete class predictions\n",
    "\n",
    "# Visualize the confusion matrix in a plot\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y, y_pred=yhat_class)  \n",
    "plt.title(f\"Confusion matrix of {type(model).__name__}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef182560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 to plot the confusion matrix: note how the method from_estimator \n",
    "# bypasses the calculation of predictions. Instead of calling predict(), \n",
    "# we can directly give the trained model as argument\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=model, X=X, y=y)\n",
    "plt.title(f\"Confusion matrix of {type(model).__name__}\")\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd43ff7",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "While inspecting a confusion matrix is useful, it is also informative to consider the specific performance indicators derived from it. The `skelarn` library provides a classification report, which includes the classifier's precision, recall, and F1-score, defined as the harmonic mean of precision and recall: $$ F_1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall} $$\n",
    "#### Exercise 3\n",
    "Locate the function the function `classification_report` from the module `sklearn.metrics` and call it to create a classification report for the logistic regression model. Interpret the obtained results and try to phrase a conclusion about the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6301fc",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "The main difference between ROC analysis and the confusion matrix, as well as accuracy indicators derived from the confusion matrix is that ROC analysis considers all possible thresholds for classifying observations. Specifically, the ROC curve is a graphical representation of the trade-off between the true positive rate (TPR) and the false positive rate (FPR) for different classification thresholds. The area under the ROC curve (AUC) is a single number summary of a classifier's ROC curve and a widely used indicator when comparing alternative classifiers.  \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Humboldt-WI/demopy/main/ROC-curve.png\" width=\"854\" height=\"480\" alt=\"Confusion Matrix\">\n",
    "\n",
    "\n",
    "### Exercise 4\n",
    "Your task is to examine the performance of the logistic regression (i.e., `model`) using ROC analysis. Specifically:\n",
    "- Import the function `roc_auc_score` and the class `RocCurveDisplay` from `sklearn.metrics` \n",
    "- Compute probabilistic predictions and store the results in a variable `yhat_proba`\n",
    "- Compute the AUC using the function `roc_auc_score` and print the result.\n",
    "- Use the the class `RocCurveDisplay` to plot an ROC curve for the logistic regression model. Note that the use of the class is identical to the `ConfusionMatrixDisplay` class, which we used earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe85b5",
   "metadata": {},
   "source": [
    "# Congratulations. You made it to the end of yet another challenging tutorial notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "B0rxPs4QEGtz",
    "27sCENzmoGcX"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bads310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
