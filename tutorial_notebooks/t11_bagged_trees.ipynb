{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/IPML/blob/master/tutorial_notebooks/t11_bagged_trees.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagged Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"bagging.gif\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(X, y):\n",
    "    bootstrap_indices = np.random.randint(low=0, high=len(X), size=len(X))\n",
    "    X_bootstrapped = X.iloc[bootstrap_indices]\n",
    "    y_bootstrapped = y.iloc[bootstrap_indices]\n",
    "    return X_bootstrapped, y_bootstrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Trees from Scratch\n",
    "\n",
    "- Initialization: Prepare a list to hold individual decision trees and another for their predictions.\n",
    "- Training:\n",
    "    - For each tree to be created, generate a bootstrap sample from the original dataset.\n",
    "    - Train a decision tree on this bootstrap sample.\n",
    "    - Store the trained tree.\n",
    "- Prediction:\n",
    "    - For a given input, use each tree in the ensemble to make a prediction.\n",
    "    - Aggregate these predictions into a final prediction. The aggregation method depends on whether the task is regression (use the average of predictions) or classification (use majority voting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bagged_trees():\n",
    "\n",
    "    def __init__(self, n_trees: int):\n",
    "        '''Class for training and predicting with a bootstrap aggregated tree ensemble for binary classification.\n",
    "    \n",
    "        Args:\n",
    "            n_trees (int): number of trees in the ensemble\n",
    "        '''\n",
    "        self.n_trees = n_trees  # initialize number of trees\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''Trains ensemble on given features and targets.\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame or np.array): Matrix of features\n",
    "            y (pd.Series or np.array): Vector of targets\n",
    "        '''\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            # create a bootstrap sample from the original dataset\n",
    "            X_bs, y_bs = bootstrapping(X, y)\n",
    "            # train one tree on the bootstrap sample and store it\n",
    "            self.trees.append(DecisionTreeClassifier().fit(X_bs, y_bs))\n",
    "        return self  # return instance of the class to enable method chaining\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''Predicts using the tree ensemble for a given set of features.\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame or np.array): Matrix of features\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Vector of continuous predictions for each observation\n",
    "            \n",
    "        Raises:\n",
    "            AttributeError if function `fit` was not run beforehand\n",
    "        '''\n",
    "        predictions = []\n",
    "        for tree in self.trees:\n",
    "            predictions.append(tree.predict(X))  # predict with each tree\n",
    "        return np.mean(predictions, axis=0) # aggregate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from the web\n",
    "url = 'https://raw.githubusercontent.com/Humboldt-WI/bads/master/data/hmeq.csv'\n",
    "df = pd.read_csv(url)  # standard pandas function to load tabular data in CSV format\n",
    "\n",
    "# Missing value handling\n",
    "for col in df.columns:  # loop through all the columns (i.e., features)\n",
    "    if df[col].dtype == 'O':  # decide on the imputation strategy based on the data type\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)  # mode replacement for categories\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)  # mean replacement for all other features \n",
    "\n",
    "# Dummy coding of the (two) categorical variables\n",
    "df = pd.get_dummies(data=df, drop_first=True)\n",
    "\n",
    "# Create default variables names X, y for further analysis\n",
    "# We use the suffix _cls to highlight that this data facilitates regression\n",
    "X = df.copy()\n",
    "y = X.pop('BAD')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC:\t0.9495\n"
     ]
    }
   ],
   "source": [
    "predictions = bagged_trees(n_trees=1000).fit(X_train, y_train).predict_proba(X_test)\n",
    "print(f'AUC ROC:\\t{roc_auc_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_preds = DecisionTreeClassifier(random_state=42).fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "bagging_preds = BaggingClassifier(n_estimators=1000, random_state=42).fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "forest_preds = RandomForestClassifier(n_estimators=1000, random_state=42).fit(X_train, y_train).predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Decision Tree AUC ROC:\t\t0.7949\n",
      "Bagged Tree Ensemble AUC ROC:\t\t0.9491\n",
      "Random Forest Ensemble AUC ROC:\t\t0.9676\n"
     ]
    }
   ],
   "source": [
    "print(f'Single Decision Tree AUC ROC:\\t\\t{roc_auc_score(y_test, tree_preds):.4f}')\n",
    "print(f'Bagged Tree Ensemble AUC ROC:\\t\\t{roc_auc_score(y_test, bagging_preds):.4f}')\n",
    "print(f'Random Forest Ensemble AUC ROC:\\t\\t{roc_auc_score(y_test, forest_preds):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tsf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
