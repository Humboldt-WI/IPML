{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/ipml/blob/master/tutorial_notebooks/4_preparing_for_machine_learning_tasks.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving to Machine Learning\n",
    "\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "This notebook continues our journey through the space of Python programming. At this point, you should be familiar with general programming concepts including variables, data types, and control structures. These concepts re-occur when we are progressing to using Python for machine learning and AI. Specifically, the notebook is to accompany the lecture on the **Foundations of Machine Learning**.\n",
    "\n",
    "Key topics:\n",
    "- Libraries for data handling: Numpy and Pandas\n",
    "- Hands-on case study: Resale Price Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is all about data\n",
    "Machine learning is a data-driven field. The two most important libraries for handling data in Python are `Numpy` and `Pandas`. If needed, you can install them by uncommenting and executing the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Numpy Library\n",
    "`Numpy`is a powerful library for scientific computing. The core data type is the `numpy.ndarray`, which represents a  **tensor**. A tensor is a multi-dimensional array that generalizes scalars (0D), vectors (1D), and matrices (2D) to higher dimensions, used to represent data in mathematics and machine learning. `Numpy` is designed to facilitate fast processing of such higher dimensional data. Let's explore how we can use the `numpy.ndarray` to store and manipulate data.\n",
    "\n",
    "## Basic data handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating arrays from lists\n",
    "array_1d = np.array([1, 2, 3, 4, 5, 6])  # 1D array\n",
    "array_2d = np.array([[1, 2, 3], [4, 5, 6]])  # 2D array\n",
    "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # 3D array\n",
    "\n",
    "print(\"We store data as: \", type(array_1d), \"\\n\")\n",
    "print(\"1D Array:\\n\", array_1d)\n",
    "print(\"\\n2D Array:\\n\", array_2d)\n",
    "print(\"\\n3D Array:\\n\", array_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays support indexing and slicing, just like lists and other Python containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing\n",
    "print(\"\\nArray indexing:\")\n",
    "print(\"Element at index 2 in array_1d:\", array_1d[2])\n",
    "print(\"Element at row 1, column 2 in array_2d:\", array_2d[1, 2])\n",
    "print(\"Element at [0, 1, 1] in array_3d:\", array_3d[0, 1, 1])\n",
    "\n",
    "# Slicing\n",
    "print(\"\\nArray slicing:\")\n",
    "print(\"First 3 elements of array_1d:\", array_1d[:3])\n",
    "print(\"Last row of array_2d:\", array_2d[-1, :])\n",
    "print(\"Slice of array_3d:\\n\", array_3d[:, :, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They also support logical indexing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logical operations\n",
    "is_even = array_1d % 2 == 0  # we have seen the modulo operation before\n",
    "print(\"Boolean mask for even numbers in array_1d:\\n\", is_even)\n",
    "print(\"Filtered even numbers from array_1d:\\n\", array_1d[is_even])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing functionality\n",
    "Furthermore, the `Numpy` library provides there is a [massive set of functions](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) to work with data of type `np.ndarray`. Here is an example where we use functions to aggregate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call a Numpy functions on an array\n",
    "print(\"Sum of array_1d:\", np.sum(array_1d))         # Numpy function to calculate sum\n",
    "print(\"Mean of array_2d:\", np.mean(array_2d))       # Numpy function to calculate mean\n",
    "print(\"Max value in array_3d:\", np.max(array_3d))   # Numpy function to calculate max value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, many functions allow you to reshape or transform your multi-dimensional data. We exemplify this by first reshaping our 1D array into a matrix and then transposing the resulting matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = array_1d.reshape(3, 2)  # Reshape 1D array to 2D array\n",
    "print(\"\\nReshaped 1D array:\\n\", matrix)\n",
    "\n",
    "# Transpose\n",
    "matrix_transpose = matrix.T\n",
    "print(\"\\nTranspose of matrix:\\n\", matrix_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two remarks concerning the programming syntax in the above demo. \n",
    "\n",
    "First, note the difference in the Python syntax. Before, we used the syntax `np.some_function(some_ndarray)` to call a function on an `ndarray`. Here, we use the syntax `some_ndarray.some_function(some_arguments)` instead. Both forms are common when working with `Numpy`. They are often exchangeable. Depending on the context, however, one version can be more readable and thus preferable to another. For example, the following lines of code are equivalent but version 1 is considered more readable: \n",
    "```Python\n",
    "np.sum(array_1d)  # Version 1; more readable\n",
    "array_1d.sum()    # Version 2; equivalent but less readable.\n",
    "```\n",
    "Second, the syntax `some_ndarray.T` is often seen in practice, although it is not very readable. It is a commonly used shorthand form for `np.transpose(some_array)`.\n",
    "\n",
    "Let's next practice the use of `Numpy` by solving some programming exercises.\n",
    "\n",
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two matrices, $A$, and $B$, as follows:\n",
    "\n",
    " $$ A = \\left( \\begin{matrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 10 \\end{matrix} \\right) \\quad\n",
    "  B = \\left( \\begin{matrix} 1 & 4 & 7 \\\\ 2 & 5 & 8 \\\\ 3 & 6 & 9 \\end{matrix} \\right)  \\quad $$\n",
    "\n",
    "  Store the variables as a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create variables A, B\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 10]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following operations.\n",
    "\n",
    "Note that mathematical operators like `*` might not behave in the way you expect or need it. For example, the result of $A*B$ depends on how you understand the multiplication sign. It could refer to the matrix product but also an element-wise multiplication (i.e. *Hadamard* product). Below, we use the notation $A \\cdot B$ to indicate the matrix product. \n",
    "\n",
    "  a. Define a variable `a`, set it to some value and calculate $a \\cdot A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=4\n",
    "a*A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  b. Calculate $A \\cdot B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(A,A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Calculate the inverse of matrix $A$ and store the result in a variable $invA$. Be assured that `Numpy` knows a function to calculate the inverse of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Multiply $A$ and $invA$ and verify that the result is the identity matrix (i.e. only 1s on the diagonal). You'll probably find that it isn't, because computers usually make very small rounding errors when handling real numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. To further investigate these rounding errors, create an identity matrix of suitable size using the `Numpy` function `eye()`. Store the result in a variable `I`. <br>Then compute $ I - A \\cdot A^{-1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Fill the first row of matrix $B$ with ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Access the second element in the third row of $A$ and the first element in the second row of $B$, and compute their product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Multiply the first row of $A$ and the third column of $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Access the elements of $B$ that are greater than 1 (without looking up their position manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. Access the elements of A in the second column, for which the values in the first column are greater or equal to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pandas Library\n",
    "Pandas is the *goto* library when it comes to storing tabular data in Python. Like numpy, it provides a core data type - actually two - and a ton of functionality to work with the corresponding data. The first core data type is the `DataFrame`. Think of it as an Excel spreadsheet or a table in a relational database. The second core type is the `Series`, which you can think of as a single column of a table (i.e.`DataFrame`). \n",
    "\n",
    "## Creating a DataFrame\n",
    "It is possible to create a `DataFrame` on-the-fly. Recall our first example of the `Numpy.ndarray`. There, we created the data by converting a `list`: \n",
    "```Python\n",
    "array_1d = np.array([1, 2, 3, 4, 5, 6])  # 1D array` \n",
    "```\n",
    "A similar approach would work for the type `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of values\n",
    "some_data = [10, 20, 30, 40, 50]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=some_data, columns=['Header'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things to note here:\n",
    "- We specified the column header in our table by setting the argument `columns`. The code would execute without setting this argument. Try it out to see why it is useful to specify a column header.\n",
    "- In the print out, we see the actual data, our column header, and an index (i.e., leftmost column without header). The index is set by default to a consecutive number. This mimics the behavior you already know from `list` and `numpy.ndarray`. We can access data using an index. In Pandas, we can manually adjust the index if needed. We will see some examples in later parts of the course. \n",
    "\n",
    "If creating a `DataFrame` on-the-fly, it is actually more common to use a `dictionary` than a `list` because the key=value paradigm of dictionaries naturally provides column headers. Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a DataFrame from a dictionary\n",
    "some_dic = {'Name': ['Peter', 'Selina', 'Bruce', 'Natascha', 'Clark', 'Diana'],\n",
    "        'Age': [22, 21, 25, 22, 23, 22]\n",
    "}\n",
    "df = pd.DataFrame(some_dic)\n",
    "df  # Display the DataFrame. Not using print() is preferable for Jupyter notebooks. The result just looks nicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DataFrames\n",
    "We could spend an entire session and more on exploring the functionality of the `Pandas` library, the `DataFrame` and `Pandas.Series`. Generally speaking, many concepts that you know from `Numpy` reoccur. Examples include indexing and slicing but also the way in which you call functions on data stored in a `DataFrame`. To just give one example, try out the following code:\n",
    "```Python\n",
    "df[\"Age\"].mean()\n",
    "\n",
    "```\n",
    "It is fairly obvious what this code does. More importantly, the example shows the syntactical similarities between `Pandas` and `Numpy`. Specifically, we first index a column by using it's name and we then call a function using dot-notation on the resulting data, that is all the age values stored in the `DataFrame`. Again, we will see many more examples of the functionality in the `Pandas` library while we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean Age over the DataFrame df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "The most important use case of `Pandas` for now is to load data sets that are already stored on a hard disk, in an Excel file, available on the web, etc. We demonstrate this operation for text data stored in *csv* format (for comma separated values). You can load data in this format using a function `read_csv()`. To load data in another common format, `Pandas` knows many more `read_xyz()` functions that work similarly. \n",
    "\n",
    "Execute the following code, which load a demo data set from our Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/Humboldt-WI/IPML/main/data/resale_price_dataset.csv'\n",
    "\n",
    "resale_data = pd.read_csv(url)\n",
    "\n",
    "# Display a preview of the data\n",
    "resale_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the resale price forecasting use case from our last lecture. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Humboldt-WI/demopy/main/model_based_resale_price_forecasting.png\" width=\"680\" height=\"400\" alt=\"Resale Price Forecasting \">\n",
    "\n",
    "The data we just loaded is a synthetic data set, which we will use in following exercises to demonstrate a resale price forecasting use case. Take a little time to familiarize yourself with the data. You already saw how you can obtain a preview of the data stored in a `DataFrame`. This is also the purpose of the `Pandas` functions `.head()` and `.tail()`. Further useful functions to obtain a first impression of a new data set include:\n",
    "- `.shape` (no brackets)\n",
    "- `.info()`\n",
    "- `.describe()` \n",
    "\n",
    "Use the following code cells to play with these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame using the head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 10 rows of the DataFrame using the tail() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the DataFrame using the shape attribute  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a summary of the DataFrame using the info() function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the describe() function on the DataFrame to get a statistical summary of the data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Judgmental vs Statistical Forecasting\n",
    "We complete this session with an exercise related to our lecture. Recall that we discussed the differences between a judgemental versus a statistical approach toward predicting resale prices of used laptops. The demo data set provides information on observed resale prices in the rightmost column `Observed resale price`. To access this data, you can index the `DataFrame` like so:\n",
    "```Python\n",
    "resale_data[\"Observed resale price\"]\n",
    "``` \n",
    "\n",
    "In a similar way, you can access the laptop's original list price, which is available in the column `Retail price` and its age. You find the latter in the column `Actual Lease Duration (months)`. \n",
    "\n",
    "**Goal**\n",
    "Implement a rule-based forecasting model. Your model should implement the business rule:\n",
    "- Resale price = 50% of the retail price if the actual lease duration > 24 months.\n",
    "- Resale price = 65% of the retail price if the actual lease duration <= 24 months.\n",
    "\n",
    "\n",
    "**Task 1**\n",
    "Write a custom function `business_rule(row)`. Assume this function receives as input a single row of the `DataFrame`. A single row represents one specific laptop. To implement the business rule, you need to use a condition and indexing. For example, to obtain the retail price of the laptop, simply type `row[\"Retail price\"]`. This is how you can use indexing for `DataFrames`. Also, you can perform mathematical operations like \n",
    "```Python\n",
    "resale_data[\"Retail price\"]*0.5\n",
    "``` \n",
    "using indexing.\n",
    "\n",
    "Your function should return a scalar value representing the rule-based forecast for the specific laptop that the function received as input, which will be either 50% or 65% of its original list price depending on the actual lease duration.\n",
    "\n",
    "**Task 2**\n",
    "Call your custom function for every laptop, that is every row of the `DataFrame`. You could write a loop for that but there is a better way. `Pandas` provides a function `.apply()`. You can this function as input the name of another function. The `.apply()` function will then call that other function for each row of the `DataFrame`, which is exactly what we need. Hence, to solve task 2, you can write: \n",
    "```Python\n",
    "resale_data['Rule-based Forecast'] = resale_data.apply(rule_based_forecast, axis=1)  # axis=1 says that we want to apply the function to every row, not every column\n",
    "```\n",
    "\n",
    "**Task 3**\n",
    "Compute the difference between the actual resale price of a laptop and the rule-based forecast. Provided you solved the previous tasks, this is easy. Simply add another column to the `DataFrame` as already illustrated for task 2, and compute this column as \n",
    "```Python\n",
    "... resale_data['Observed resale price'] - resale_data['Rule-based Forecast']. \n",
    "```\n",
    "What would be a better name the difference you just computed?\n",
    "\n",
    "**Task 4**\n",
    "Last, execute the following code to create a plot of your calculated differences between observed and predicted resale prices:\n",
    "```Python\n",
    "resale_data[\"Name_of_your_column\"].hist()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes your your solution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
