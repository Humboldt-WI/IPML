{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f330ef1b",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/ipml/blob/master/tutorial_notebooks/7_eda_tasks.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992007e",
   "metadata": {},
   "source": [
    "# Explanatory Data Analysis\n",
    "\n",
    "<hr>\n",
    "<br>\n",
    "The notebook revisits our lecture on EDA and data preparation. We will focus on the EDA part and use standard Python libraries for data visualization including `matplotlib` and `seaborn`. In this scope, we will also re-introduce concepts basic concepts from the reals of multivariate statistics. \n",
    "\n",
    "The notebook uses a data set related to credit risk modeling.\n",
    "\n",
    "Before moving on, let's import some of our standard library so that we have them ready when we need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8c2a1c57-d951-41ff-9b95-f38ffa1c5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2531067-7af4-4abb-906f-d0b475b89124",
   "metadata": {},
   "source": [
    "# The HMEQ data set\n",
    "Our data set, called the  \"Home Equity\" or, in brief, HMEQ data set, is provided by www.creditriskanalytics.net. It comprises  information about a set of borrowers, which are categorized along demographic variables and variables concerning their business relationship with the lender. A binary target variable called 'BAD' is  provided and indicates whether a borrower has repaid her/his debt. You can think of the data as a standard use case of binary classification.\n",
    "\n",
    "You can obtain the data, together with other interesting finance data sets, directly from www.creditriskanalytics.net. The website also provides a brief description of the data set. Specifically, the data set consists of 5,960 observations and 13 features including the target variable. The variables are defined as follows:\n",
    "\n",
    "- BAD: the target variable, 1=default; 0=non-default \n",
    "- LOAN: amount of the loan request\n",
    "- MORTDUE: amount due on an existing mortgage\n",
    "- VALUE: value of current property\n",
    "- REASON: DebtCon=debt consolidation; HomeImp=home improvement\n",
    "- JOB: occupational categories\n",
    "- YOJ: years at present job\n",
    "- DEROG: number of major derogatory reports\n",
    "- DELINQ: number of delinquent credit lines\n",
    "- CLAGE: age of oldest credit line in months\n",
    "- NINQ: number of recent credit inquiries\n",
    "- CLNO: number of credit lines\n",
    "- DEBTINC: debt-to-income ratio\n",
    "\n",
    "As you can see, the features aim at describing the financial situation of a borrower. We will keep using the data set in future tutorials. Therefore, it makes sense to familiarize yourself with the above features.\n",
    "\n",
    "## Loading the data\n",
    "Let's start by loading the data and taking a look at the some entries. For simplicity, we provide a version in our [GitHub repository](https://github.com/Humboldt-WI/IPML/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccd0b0-65f1-4a46-89fb-1f880d5b1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HMEQ Data from our GitHub\n",
    "url = 'https://raw.githubusercontent.com/Humboldt-WI/IPML/master/data/hmeq.csv'\n",
    "hmeq = pd.read_csv(url)\n",
    "\n",
    "# Some type conversion; just ignore for now\n",
    "hmeq.JOB = hmeq.JOB.astype('category')\n",
    "hmeq.REASON = hmeq.REASON.astype('category')\n",
    "hmeq.LOAN = hmeq.LOAN.astype('float64')\n",
    "hmeq.BAD = hmeq.BAD.astype('bool')\n",
    "\n",
    "# Preview some entries\n",
    "hmeq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3193d8e",
   "metadata": {},
   "source": [
    "## Pandas revisited\n",
    "Recall that we have been using the `Pandas` library for a while. Back then in [tutorial 4, preparing for machine learning](https://github.com/Humboldt-WI/IPML/blob/main/tutorial_notebooks/4_preparing_for_machine_learning_tasks.ipynb), we introduced the methods `.info()` and `.describe()` to get a quick overview of the data. Below, we apply them to the HMEQ data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473e1cb-e6c0-40e1-8505-bd00ec420667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the columns (i.e., features) in the data \n",
    "# and obtain some structural information\n",
    "hmeq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a statistical summary of the data, we can use the describe method\n",
    "hmeq.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0646c2",
   "metadata": {},
   "source": [
    "Note the row indices in the output of the `.describe()` method. They indicate what descriptive statistics have been calculated. For example, the row index 'mean' shows the mean value of each feature, whereby `.describe()` ignores non-numerical features by default.\n",
    "\n",
    "### Mini-Exercise\n",
    "Intepreting the output of the `.describe()` method, is complicated by the fact that the numbers are shown with high precision. Apply the method `.round()` to the output to round numbers to 2 digits of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to the mini-exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae280de7",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "What insights can we obtain from the descriptive statistics? What do the numbers tell us about the data set? Note down your observations in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a6d4a4",
   "metadata": {},
   "source": [
    "Space for your observations:\n",
    "- ...\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebfd12a",
   "metadata": {},
   "source": [
    "### Navigating data\n",
    "We discussed indexing and slicing in the contexts of Python `lists` and other containers like dictionaries. In `Pandas`, `Numpy`, and other libraries, indexing/slicing are equally important and work in similar ways. Here, we provide a few more demos on common ways to use indexing in `Pandas`. A web search for \"pandas data frame indexing\" will provide many additional insights if you are interested. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9250b4",
   "metadata": {},
   "source": [
    "### Basic indexing of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eca6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a single column by name\n",
    "hmeq['BAD']\n",
    "# Alternatively, you can access a single column using dot-notation\n",
    "hmeq.BAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c25213",
   "metadata": {},
   "source": [
    "For the *R* programmers: we can index our data in a way similar to *R*. Note the use of `loc[]`. This is a special type of syntax you need to memorize. Also note that we specify the columns we want to index using a `list`. Hence the inner box bracket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-style indexing of selected rows and columns\n",
    "hmeq.loc[0:4, [\"BAD\", \"LOAN\"]]  # select row 0, 1, 2, 3 and for those rows only the columns BAD and LOAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ab3e5",
   "metadata": {},
   "source": [
    "To access rows or columns using a numerical index, we can use the `iloc[]` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af522325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access columns by a numerical index using .iloc\n",
    "hmeq.iloc[0:4, 0]  # select row 0, 1, 2, 3 and for those rows only the first column\n",
    "hmeq.iloc[0:4, [0, 3, 5]]  # select row 0, 1, 2, 3 and for those rows only the columns 0, 3, 5\n",
    "hmeq.iloc[0:4, np.arange(4)]  # select row 0, 1, 2, 3 and for those rows only the first four columns    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b45c4b",
   "metadata": {},
   "source": [
    "A few cautionary notes on numerical indexing in Python. The `loc()` method considers the index of the data frame. In the above output, this is the left-most column without header. We have not defined a custom row index and Python uses consecutive integer numbers by default. Thus, calls to `loc()` and `iloc()` look more similar than they are. A data frame could also have a custom index. For example, the data frame returned from calling `describe()` (see above) uses a custom row index with values *count*, *mean*, *std*, etc. To deepen your understanding of the differences in data frame indexing, solve the following exercise. \n",
    "\n",
    "#### Exercise 2:\n",
    "- Execute the command `df = hmeq.describe()` to create a new data frame `df` that stores the result of the `describe()` method.\n",
    "- Use the method `df.loc[]` to access the standard deviation of the feature MORTDUE. Print out the result.\n",
    "- Use the method `df.iloc[]` to access and print out the same figure, i.e. the standard deviation of the feature MORTDUE.\n",
    "- Using `loc[]` access and print out the mean of the features LOAN, VALUE, and DEROG.  \n",
    "- Using `iloc[]` access and print out the minimum value of all features. Make use of the `:` operator to select all columns. \n",
    "- Using `loc[]` access and print out the values of the first, second, and third quartile of the distribution of the features LOAN, YOJ, and DEBTINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b684c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions to exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d30e67",
   "metadata": {},
   "source": [
    "### Other common forms of indexing and subset selection\n",
    "It is also common practice to select rows based on comparisons of feature values using `.loc`. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e30809",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmeq.loc[hmeq.BAD == True, :]  # Get all observations with target variable BAD = 1. The : means you want to retrieve all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmeq.loc[hmeq[\"NINQ\"]>12, [\"LOAN\", \"VALUE\", \"NINQ\"]]  # Another example where we select only a subset of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd52e8a-7314-403a-b3ee-67f8f9817d19",
   "metadata": {},
   "source": [
    "# Grouping data\n",
    "Grouping data is a common operation in data analysis. It is often used in combination with aggregation functions like `sum()`, `mean()`, `count()`, etc. While previous demos and exercises have looked into the mean and standard deviation of features, it would be very interesting to perform this analysis for good and bad payers separately. For example, a plausible hypothesis in credit risk modeling is that the ratio of debt to income (i.e., feature DEBTINC) is a predictor of credit risk. We would thus expect that the mean debt-to-income ration is higher for bad payers. Grouping allows us to verify such a hypothesis. \n",
    "\n",
    "The `groupby()` method in `Pandas` is a powerful tool for grouping data. Below, we provide a few examples of how to use the `groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39433974-41a5-43e5-9713-0a2469128997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = [\"LOAN\", \"DEBTINC\"]  # Define a list of features\n",
    "print(hmeq.groupby(\"BAD\")[features].mean())  # Calculate the mean of the features for each group of BAD\n",
    "print('-' * 50)\n",
    "print(hmeq.groupby(\"BAD\")[features].std())\n",
    "print('-' * 50)\n",
    "print(hmeq.groupby(\"BAD\")[features].quantile(q=0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f0615",
   "metadata": {},
   "source": [
    "# Categorical features\n",
    "Thus far, we have focused on numerical features. However, the HMEQ data set also contains categorical features. In the context of credit risk modeling, the features REASON and JOB are of particular interest. The feature REASON indicates the reason for the loan request, while the feature JOB indicates the occupation of the borrower.\n",
    "\n",
    "A typical EDA question is to investigate the distribution of categorical features. We can use the `value_counts()` method to count the number of occurrences of each category. Furthermore, we can again make use of grouping to examine the distribution of category levels across good and bad payers (i.e., values of our target).\n",
    "\n",
    "Below, we provide a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the distribution of the REASON feature\n",
    "hmeq[\"REASON\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1f62e-3acf-4918-bdad-c4d6011b2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of the BAD and REASON feature\n",
    "pd.crosstab(hmeq.BAD, hmeq.REASON)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676efb8",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "- Consider the feature DEBTINC. Use the `groupby()` method to compare the median debt-to-income ratio among good and bad payers. \n",
    "- Create a cross-table of the features BAD and JOB. \n",
    "- Recreate the cross-table of BAD vs. JOB. Make sure that it does not show absolute counts but relative frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4212b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9750b97-f4a3-4d70-be5b-32bcaddcedee",
   "metadata": {},
   "source": [
    "# Common EDA Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce19ea-5070-43e4-81f0-cac755b515a6",
   "metadata": {},
   "source": [
    "## Histograms and Count plots\n",
    "Histograms are a common visualization tool to understand the distribution of numerical features. In the context of credit risk modeling, it is important to understand the distribution of features like DEBTINC, LOAN, and VALUE. Below, we provide a few examples of how to create histograms using `seaborn` library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a100b5-a71d-42f0-9b36-44a2428446b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the feature LOAN \n",
    "sns.histplot(hmeq.LOAN)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438968ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(hmeq.LOAN, kde=True)  # Add a kernel density estimate\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a92b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the feature LOAN while specifying the number of bins \n",
    "sns.histplot(hmeq.LOAN, bins=20)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd83267-86da-4de9-bb04-93e83980f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the histogram of the LOAN feature by the target variable BAD and creating a histogram of the feature LOAN\n",
    "sns.histplot(data=hmeq, x='LOAN', hue='BAD')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79878119",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "Count plots are a visualization tool similar to the histogram but suitable for categorical. Using `seaborn`, their creation follows the same logic as exemplified above. Give it a try. Specifically:\n",
    "- Create a count plot for the feature REASON.\n",
    "- Create a count plot for the feature JOB grouped by the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b81d17",
   "metadata": {},
   "source": [
    "## Box plots\n",
    "Box plots are a powerful visualization tool to understand the distribution of numerical features across different categories. Some consider the box plot the most important visualization in data science. While this opinion is debatable, the importance of the box-plot cannot be underestimated. Let's begin with some examples of how to create a box plot using `seaborn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34807365-d5ae-4139-bb34-7c2faf745471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simple boxplot of the feature LOAN\n",
    "sns.boxplot(data=hmeq, y='LOAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ccab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of the feature LOAN in which we set the threshold for outliers to be 3 times the IQR\n",
    "sns.boxplot(data=hmeq, y='LOAN', whis=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63160f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of the feature LOAN grouped by the target variable BAD\n",
    "sns.boxplot(data=hmeq, y='LOAN', x='BAD') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd2b0b6",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "Drawing on the above demos, solve the following exercises:\n",
    "- Create a box plot for the feature VALUE.\n",
    "- Create a box plot for the feature DEBTINC grouped by the target variable.\n",
    "- Create a boxplot for the feature MORTDUE and set the threshold for outliers to be 2 times the IQR\n",
    "- Create a boxplot for the feature LOAN grouped by the feature REASON\n",
    "- Manually compute the IQR for the feature LOAN as well as the boundaries for upper and lower outliers using Tukey's rule (i.e. with a threshold of 1.5 times the IQR). Compare the results with the boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7313b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to exercise 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3886d888-8e81-486e-a220-f81fbc026aca",
   "metadata": {},
   "source": [
    "### Violin Plots\n",
    "Violin plots are a combination of box plots and kernel density plots. They provide a more detailed view of the distribution of numerical features across different categories. Arguably, this type of visualization is less common. However, it can be useful and so we complete this part with a few demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe0ab3-f28a-4985-9803-5aab3e1325f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of the feature LOAN grouped by the feature JOB\n",
    "sns.violinplot(data=hmeq, x='JOB', y='LOAN') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742225e-86a4-4a55-b94e-25987d3975b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the violins by the target variable BAD\n",
    "sns.violinplot(data=hmeq, x='JOB', y='LOAN', hue='BAD', split=True, inner='quart') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02db47-1475-4651-af0b-0110db294b73",
   "metadata": {},
   "source": [
    "## Correlation Matrix\n",
    "Correlation is a key concept in multivariate analysis. It measures the strength and direction of a linear relationship between two numerical variables. The correlation coefficient ranges from -1 to 1. A value of 1 indicates a perfect positive linear relationship, while a value of -1 indicates a perfect negative linear relationship. A value of 0 indicates no linear relationship.\n",
    "\n",
    "In a data set like our HMEQ data set, it is important to understand the correlation between features. For example, a high correlation between two features could indicate multicollinearity. This is a problem in regression analysis, as it can lead to unstable estimates of the regression coefficients. The correlation of features with the target variable is of key interest. For example, a high correlation between a feature and the target variable could indicate that the feature is a good predictor of the target.\n",
    "\n",
    "To calculate the correlation matrix, we can use the `corr()` method in `Pandas`. Note that this method will throw an error if it received non-numerical data. Therefore, we first select features based on their data type using the method `select_dtypes()`. Excluding categorical features (i.e., REASON and JOB), avoids problems when applying the `corr()` method. As result, we obtain a data frame with all pairwise correlation among the numerical features including the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= hmeq.select_dtypes(exclude='category').corr()\n",
    "corr.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941e8cd",
   "metadata": {},
   "source": [
    "Looking at large tables of numbers is cumbersome. We can visualize the correlation matrix using a heatmap. The `seaborn` library provides a convenient method for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafba5bd-c65b-4888-a8b9-292ae9a6d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(12, 8))  # The correlation matrix needs some space. So we set the size of the plot explicitly\n",
    "sns.heatmap(corr, annot=True, linewidth=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f4712",
   "metadata": {},
   "source": [
    "While better than looking at the raw numbers, the correlation matrix is still a bit hard to interpret. We can improve the visualization by highlighting high correlations (e.g., higher than a user-defined threshold). To achieve this, we can use the `mask` argument in the `heatmap()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask of correlations above a user-specified threshold\n",
    "threshold = 0.20\n",
    "mask = (corr <= threshold) & (corr >= -threshold)\n",
    "f,ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True, mask=mask, linewidth=.5)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
