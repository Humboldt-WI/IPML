{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/ipml/blob/master/tutorial_notebooks/5_SML_for_regression_solutions.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning for Regression\n",
    "\n",
    "<span style=\"color:red; font-weight: bold;\"> This notebook includes solutions to all programming tasks.</span>\n",
    "\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "This notebook revisits the lecture on **Supervised Machine Learning (SML) for Regression**. There, we studied the famous linear regression model in a resales price forecasting context, and discussed the difference between explanatory and predictive modeling. This notebook revisits the concepts and exemplify relevant steps.\n",
    "\n",
    "Key topics:\n",
    "- Preliminaries\n",
    "    - Libraries\n",
    "    - Resale price forecasting data set\n",
    "    - Preparing a simplified data set with only a few numerical features\n",
    "- Linear Regression in various flavors\n",
    "    - Computing the OLS estimator *by hand*\n",
    "    - The `statsmodels` library\n",
    "    - The `sklearn` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "Before starting with the main content, we load some standard libraries and our data. For the latter task, we reuse the content from the previous tutorial. Recall that our synthetic resale price modeling data set is readily available in our [GitHub repository](https://github.com/Humboldt-WI/IPML). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Release year</th>\n",
       "      <th>Screen size (inches)</th>\n",
       "      <th>Hard drive size (GB)</th>\n",
       "      <th>RAM size (GB)</th>\n",
       "      <th>Weight (grams)</th>\n",
       "      <th>Retail price</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Contract Lease Duration (months)</th>\n",
       "      <th>Actual Lease Duration (months)</th>\n",
       "      <th>Battery capacity (%)</th>\n",
       "      <th>Observed resale price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crest</td>\n",
       "      <td>Elevation Elite</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>1150</td>\n",
       "      <td>2699</td>\n",
       "      <td>Automotive and Transportation</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>87.90</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crest</td>\n",
       "      <td>Elevation Elite</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>1150</td>\n",
       "      <td>2719</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>95.59</td>\n",
       "      <td>2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crest</td>\n",
       "      <td>Elevation Elite</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>1150</td>\n",
       "      <td>2759</td>\n",
       "      <td>Automotive and Transportation</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>95.05</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crest</td>\n",
       "      <td>Elevation Elite</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>1150</td>\n",
       "      <td>2639</td>\n",
       "      <td>Automotive and Transportation</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>94.66</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crest</td>\n",
       "      <td>Elevation Elite</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>1150</td>\n",
       "      <td>2659</td>\n",
       "      <td>Agriculture and Farming</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>89.12</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>WindRider W2</td>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>1028</td>\n",
       "      <td>16</td>\n",
       "      <td>958</td>\n",
       "      <td>3989</td>\n",
       "      <td>Event Management</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>94.81</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>WindRider W2</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>8</td>\n",
       "      <td>830</td>\n",
       "      <td>2859</td>\n",
       "      <td>Aerospace and Defense</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>85.46</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>WindRider W2</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>8</td>\n",
       "      <td>830</td>\n",
       "      <td>2859</td>\n",
       "      <td>Construction and Engineering</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>95.02</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>WindRider W2</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>8</td>\n",
       "      <td>830</td>\n",
       "      <td>2829</td>\n",
       "      <td>Automotive and Transportation</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>92.36</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>WindRider W2</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>8</td>\n",
       "      <td>830</td>\n",
       "      <td>2949</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>77.45</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand            Model  Release year  Screen size (inches)  \\\n",
       "0      Crest  Elevation Elite          2016                    15   \n",
       "1      Crest  Elevation Elite          2016                    15   \n",
       "2      Crest  Elevation Elite          2016                    15   \n",
       "3      Crest  Elevation Elite          2016                    15   \n",
       "4      Crest  Elevation Elite          2016                    15   \n",
       "...      ...              ...           ...                   ...   \n",
       "4995  Zephyr     WindRider W2          2017                    15   \n",
       "4996  Zephyr     WindRider W2          2017                    13   \n",
       "4997  Zephyr     WindRider W2          2017                    13   \n",
       "4998  Zephyr     WindRider W2          2017                    13   \n",
       "4999  Zephyr     WindRider W2          2017                    13   \n",
       "\n",
       "      Hard drive size (GB)  RAM size (GB)  Weight (grams)  Retail price  \\\n",
       "0                      512             16            1150          2699   \n",
       "1                      512             16            1150          2719   \n",
       "2                      512             16            1150          2759   \n",
       "3                      512             16            1150          2639   \n",
       "4                      512             16            1150          2659   \n",
       "...                    ...            ...             ...           ...   \n",
       "4995                  1028             16             958          3989   \n",
       "4996                  1028              8             830          2859   \n",
       "4997                  1028              8             830          2859   \n",
       "4998                  1028              8             830          2829   \n",
       "4999                  1028              8             830          2949   \n",
       "\n",
       "                           Industry  Contract Lease Duration (months)  \\\n",
       "0     Automotive and Transportation                                60   \n",
       "1                        Healthcare                                 6   \n",
       "2     Automotive and Transportation                                24   \n",
       "3     Automotive and Transportation                                36   \n",
       "4           Agriculture and Farming                                12   \n",
       "...                             ...                               ...   \n",
       "4995               Event Management                                48   \n",
       "4996          Aerospace and Defense                                36   \n",
       "4997   Construction and Engineering                                12   \n",
       "4998  Automotive and Transportation                                60   \n",
       "4999                     Consulting                                12   \n",
       "\n",
       "      Actual Lease Duration (months)  Battery capacity (%)  \\\n",
       "0                                 63                 87.90   \n",
       "1                                  5                 95.59   \n",
       "2                                 27                 95.05   \n",
       "3                                 31                 94.66   \n",
       "4                                 10                 89.12   \n",
       "...                              ...                   ...   \n",
       "4995                              48                 94.81   \n",
       "4996                              34                 85.46   \n",
       "4997                              10                 95.02   \n",
       "4998                              65                 92.36   \n",
       "4999                              11                 77.45   \n",
       "\n",
       "      Observed resale price  \n",
       "0                       751  \n",
       "1                      2599  \n",
       "2                      1358  \n",
       "3                      1166  \n",
       "4                      1915  \n",
       "...                     ...  \n",
       "4995                   1334  \n",
       "4996                    988  \n",
       "4997                   1967  \n",
       "4998                    879  \n",
       "4999                   1776  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load resale price forecasting data set from GitHub    \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Humboldt-WI/IPML/main/data/resale_price_dataset.csv'\n",
    "resale_data = pd.read_csv(url)\n",
    "\n",
    "# Display a preview of the data\n",
    "resale_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comprises categorical and numerical features. The former need special treatment when using them for regression analysis. In the interest of simplicity, we will begin with creating a subset of the data containing only the numerical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Release year                      5000 non-null   int64  \n",
      " 1   Screen size (inches)              5000 non-null   int64  \n",
      " 2   Hard drive size (GB)              5000 non-null   int64  \n",
      " 3   RAM size (GB)                     5000 non-null   int64  \n",
      " 4   Weight (grams)                    5000 non-null   int64  \n",
      " 5   Retail price                      5000 non-null   int64  \n",
      " 6   Contract Lease Duration (months)  5000 non-null   int64  \n",
      " 7   Actual Lease Duration (months)    5000 non-null   int64  \n",
      " 8   Battery capacity (%)              5000 non-null   float64\n",
      " 9   Observed resale price             5000 non-null   int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 390.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Create new data set including only the numerical features\n",
    "df = resale_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Verify the new data includes only numerical features\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "The lecture introduced the famous linear regression model. Recall the linear equation for the multivariate regression model: \n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n + \\epsilon$$\n",
    "\n",
    "where:  \n",
    "- $Y$ is the target variable\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_m$ are the coefficients of the $m$ features $X_1, X_2, \\ldots, X_m$\n",
    "\n",
    "In this part, we start by computing the ordinary least squares (OLS) estimator using `Numpy`. This is to further advance our programming skills. Later, we introduce the library `statsmodels` to perform regression analysis. \n",
    "\n",
    "To remain consistent with our standard notation, we first create separate variables to store the feature matrix $\\mathbf{X}$ and the target variable $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for regression\n",
    "y = df['Observed resale price']\n",
    "X = df.drop('Observed resale price', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lecture introduced the normal equation for linear regression given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{\\hat{\\beta}}$ is the vector of estimated coefficients,\n",
    "- $\\mathbf{X}$ is the feature matrix,\n",
    "- $\\mathbf{Y}$ is the target variable vector.\n",
    "\n",
    "We can compute this estimator using `Numpy` functions.\n",
    "\n",
    "### Exercises 1: Linear regression from scratch\n",
    "1. Create a function `ols_estimator` that computes the OLS estimator given the feature matrix `X` and the target variable vector `y`.\n",
    "2. Create a function `predict` that computes the predicted values given the feature matrix `X` and the estimated coefficients `beta_hat`. \n",
    "3. Create a function `r_squared` that computes the coefficient of determination as follows:\n",
    "$$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $$\n",
    "with $\\bar{y}$ being the mean of the target variable vector `y`, and $\\hat{y}_i$ being the predicted value.\n",
    "\n",
    "4. Add a column of ones to the feature matrix $\\mathbf{X}$. This is mathematically equivalent to adding an intercept $\\beta_0$ to the regression function. `Numpy` provides a function `ones()` that you can use to create a tensor with all elements being 1. You only need to specify the tensor's dimensionality. Another useful `Numpy` function is `.c_`. It allows you to concatenate two tensors along a specific axis. For example, if you have two tensors `a` and `b`, you can concatenate them along the second axis by writing `np.c_[a, b]`. \n",
    "5. Putting everything together<br>\n",
    "  a. Using the augmented feature matrix from subtask 4, compute the OLS estimator using the function `ols_estimator` and the target variable vector `y`.<br>\n",
    "  b. Using the estimated coefficients, compute regression predictions using your function `predict`. <br>\n",
    "  c. Finally, compute the $R^2$ of your regression function using the `r_squared`. <br>\n",
    "\n",
    "> Hints:\n",
    "> Use the `Numpy` function `transpose` to transpose a matrix. Alternatively, if variable `X` is a matrix, you can write `X.T` to obtain its transpose.\n",
    "> Use the `Numpy` function `dot` for matrix multiplication.  \n",
    "> Use the `Numpy` function `inv` to compute the inverse of a matrix. Note that this function is in the `linalg` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1\n",
    "def ols_estimator(X, y):\n",
    "    \"\"\"\n",
    "    Compute the OLS estimator given the feature matrix X and the target variable vector y.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix\n",
    "    y (numpy.ndarray): Target variable vector\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Estimated coefficients\n",
    "    \"\"\"\n",
    "    tmp = np.linalg.inv(np.dot(X.T, X))  # compute the estimator step by step\n",
    "    return  np.dot( np.dot(tmp, X.T) , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "def ols_predictor(X, beta_hat):\n",
    "    \"\"\"\n",
    "    Compute the OLS prediction given the feature matrix X and the estimated coefficients beta_hat.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix\n",
    "    beta_hat (numpy.ndarray): Estimated coefficients\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Predicted values\n",
    "    \"\"\"\n",
    "    return np.dot(X, beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "def r_squared(y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the R-squared of the OLS prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    y (numpy.ndarray): True target variable vector\n",
    "    y_pred (numpy.ndarray): Predicted target variable vector\n",
    "    \n",
    "    Returns:\n",
    "    float: R-squared\n",
    "    \"\"\"\n",
    "    return 1 - np.sum((y - y_pred) ** 2) / np.sum((y - np.mean(y)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Augment feature matrix with a column of 1\n",
    "X_aug = np.c_[np.ones(X.shape[0]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates: [-1.32195565e+03  6.31705234e-01 -2.55055713e+01 -7.21029320e-01\n",
      " -2.16317994e+01 -1.51988790e-01  7.94818235e-01 -9.80390226e+00\n",
      " -1.02573751e+01  1.20479194e+01]\n",
      "R-squared: 0.86835661100624\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Putting everything together\n",
    "beta_hat = ols_estimator(X_aug, y)\n",
    "y_pred = ols_predictor(X_aug, beta_hat)\n",
    "r2 = r_squared(y, y_pred)\n",
    "\n",
    "# Print the coefficient estimates\n",
    "print(f'Coefficient estimates: {beta_hat}')\n",
    "\n",
    "# Print the R-squared\n",
    "print(f'R-squared: {r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Library Statsmodels\n",
    "While being a useful exercise to develop coding skills, in practice, we would not implement linear regression from scratch. Instead, we would use a library that provides a wide range of functionalities for regression analysis. One such library is `statsmodels`. \n",
    "\n",
    "The following demo shows how to use `statsmodels` to perform linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     Observed resale price   R-squared:                       0.868\n",
      "Model:                               OLS   Adj. R-squared:                  0.868\n",
      "Method:                    Least Squares   F-statistic:                     3657.\n",
      "Date:                   Tue, 10 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                           17:10:34   Log-Likelihood:                -34403.\n",
      "No. Observations:                   5000   AIC:                         6.883e+04\n",
      "Df Residuals:                       4990   BIC:                         6.889e+04\n",
      "Df Model:                              9                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                            -1321.9557   7105.441     -0.186      0.852   -1.53e+04    1.26e+04\n",
      "Release year                         0.6317      3.523      0.179      0.858      -6.275       7.538\n",
      "Screen size (inches)               -25.5056      4.454     -5.726      0.000     -34.237     -16.774\n",
      "Hard drive size (GB)                -0.7210      0.037    -19.493      0.000      -0.794      -0.649\n",
      "RAM size (GB)                      -21.6318      1.402    -15.434      0.000     -24.379     -18.884\n",
      "Weight (grams)                      -0.1520      0.046     -3.305      0.001      -0.242      -0.062\n",
      "Retail price                         0.7948      0.016     49.592      0.000       0.763       0.826\n",
      "Contract Lease Duration (months)    -9.8039      1.043     -9.399      0.000     -11.849      -7.759\n",
      "Actual Lease Duration (months)     -10.2574      1.028     -9.977      0.000     -12.273      -8.242\n",
      "Battery capacity (%)                12.0479      0.552     21.841      0.000      10.967      13.129\n",
      "==============================================================================\n",
      "Omnibus:                      753.577   Durbin-Watson:                   1.922\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1584.307\n",
      "Skew:                           0.903   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.084   Cond. No.                     7.09e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.09e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant term to the feature matrix X\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression output provides a lot of information. For instance, it includes the estimated coefficients, their standard errors, t-values, p-values, and confidence intervals. Of course, you also find the $R^2$ and adjusted $R^2$ values, as well as the F-statistic and its p-value. Recall that these statistics assess the model as a whole. It is worth examining the output in detail and to make sure you understand the meaning of key statistics. Interpreting the results of a regression analysis is a crucial skill for researchers and data scientists.\n",
    "\n",
    "### Exercise 2: Coefficient estimates\n",
    "Given that we implemented the normal equation in exercise 1, we can expect that the estimate coefficients are the same as those coming from `statsmodels`. To check this, compute the difference between the two estimates, the `beta_hat` that you calculated in task 1 of exercise 1 and the estimated coefficients from `statsmodels`. To achieve this, you need to search the library's documentation to find a way to access the estimated coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.42551458e-06, -2.86517121e-09, -7.68451969e-11,  1.51989532e-13,\n",
       "        2.67590394e-11,  1.05693232e-12, -7.86037901e-14, -1.82609483e-12,\n",
       "        2.65210076e-12,  1.24344979e-13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated coefficients from statsmodels\n",
    "beta_hat_sm = model.params.values\n",
    "\n",
    "# Difference between the estimates\n",
    "beta_hat - beta_hat_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Compute forecasts\n",
    "To be fair, our `statsmodels` demo leaves out one bit of functionality. We obtain the coefficients and the $R^2$ value right from estimating the model but have never computed predictions. Let's finish this demo by studying how `statsmodels` would allow us to do so. Specifically, compute predictions `y_hat_sm` for your `statsmodels` regression model. Then (re-)calculate the $R^2$ of the model using your custom function `r_squared`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.8683566110062401\n"
     ]
    }
   ],
   "source": [
    "# Predictions from statsmodels\n",
    "yhat_sm = model.predict(X_const)\n",
    "\n",
    "r2_sm = r_squared(y, yhat_sm)\n",
    "\n",
    "print(f'R-squared: {r2_sm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Library `sklearn`\n",
    "The library `sklearn` is the *goto* library for machine learning in Python. It provides a wide range of machine learning functionalities, including regression. For regression analysis, that is explanatory model, `sklearn` is a bad choice and offers far less functionality than `statsmodels`. We still demonstrate its use because the way in which we apply `sklearn` to perform regression is identical to the way in which we would use `sklearn` for other, more advanced learning algorithms. Thus, it is useful to familiarize yourself with the key `sklearn` functions `fit()` and `predict()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates: [  0.63170524 -25.50557135  -0.72102932 -21.63179936  -0.15198879\n",
      "   0.79481824  -9.80390226 -10.25737509  12.04791938]\n",
      "Intercept: -1321.9556608133712\n",
      "R-squared: 0.8683566110062401\n"
     ]
    }
   ],
   "source": [
    "# Load the library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an instance of the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)  # No need to add a constant term. This is done automatically, and controlled by the parameter fit_intercept of the fit() method.\n",
    "\n",
    "# Compute predictions\n",
    "y_pred_sklearn = model.predict(X)\n",
    "\n",
    "# Print the coefficient estimates\n",
    "print(f'Coefficient estimates: {model.coef_}')\n",
    "\n",
    "# Print the intercept   \n",
    "print(f'Intercept: {model.intercept_}')\n",
    "\n",
    "# Print the R-squared\n",
    "r2_sklearn = model.score(X, y)  # Compute R-squared. You could also use your custom function r_squared() here.\n",
    "print(f'R-squared: {r2_sklearn}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
